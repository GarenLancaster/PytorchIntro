{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIT实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device(\"cuda\"if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size=64\n",
    "new_workers=4\n",
    "lr=1e-4\n",
    "epochs=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接pytroch下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "image_size=28\n",
    "data_transforms=transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data=datasets.FashionMNIST('datasets',train=True,transform=data_transforms,download=True)\n",
    "test_data=datasets.FashionMNIST('datasets',train=False,transform=data_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由CSV制作数据集\n",
    "\n",
    "这里假设输入数据是pandas的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMDataset(Dataset):\n",
    "    def __init__(self,df,transforms=None):\n",
    "        self.df=df\n",
    "        self.transforms=transforms\n",
    "        self.images=df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels=df.iloc[:,0].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index].reshape(28,28,1)\n",
    "        label=int(self.labels[index])\n",
    "        if(self.transforms is None):\n",
    "           image=torch.tensor(image/255,dtype=torch.float)\n",
    "        else:\n",
    "            image=self.transforms(image)\n",
    "        label=torch.tensor(label,dtype=torch.int)\n",
    "        return image,label\n",
    "\n",
    "# 上面还有一个train和test的分类没写\n",
    "# train_df=pd.read_csv('...') \n",
    "# test_df=pd.read_csv('...')   \n",
    "# train_data=FMDataset(train_df,data_transforms)\n",
    "# test_data=FMDataset(test_df,data_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 装载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader参数pin_memory：增加运行速度消耗更多内存。这次先不用\n",
    "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=new_workers,drop_last=True)\n",
    "test_loader=DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=new_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe0c7daea0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image,label=next(iter(train_loader))\n",
    "print(image.shape,label.shape)\n",
    "plt.imshow(image[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继承nn.Module，构造一个简单的卷积网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(1,32,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(64*4*4,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        \n",
    "        x=x.view(-1,64*4*4)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "   \n",
    "    # 校验Conv的输出再判断self.fc如何设计\n",
    "    def TestConv(self):\n",
    "        print(self.conv(torch.rand([1,28,28])).shape)\n",
    "\n",
    "Net().TestConv()\n",
    "model=Net()\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "This criterion computes the cross entropy loss between input logits\n",
      "and target.\n",
      "\n",
      "It is useful when training a classification problem with `C` classes.\n",
      "If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
      "assigning weight to each of the classes.\n",
      "This is particularly useful when you have an unbalanced training set.\n",
      "\n",
      "The `input` is expected to contain the unnormalized logits for each class (which do `not` need\n",
      "to be positive or sum to 1, in general).\n",
      "`input` has to be a Tensor of size :math:`(C)` for unbatched input,\n",
      ":math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n",
      "`K`-dimensional case. The last being useful for higher dimension inputs, such\n",
      "as computing cross entropy loss per-pixel for 2D images.\n",
      "\n",
      "The `target` that this criterion expects should contain either:\n",
      "\n",
      "- Class indices in the range :math:`[0, C)` where :math:`C` is the number of classes; if\n",
      "  `ignore_index` is specified, this loss also accepts this class index (this index\n",
      "  may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n",
      "  set to ``'none'``) loss for this case can be described as:\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "      l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
      "      \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
      "\n",
      "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = \\begin{cases}\n",
      "          \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n",
      "           \\text{if reduction} = \\text{`mean';}\\\\\n",
      "            \\sum_{n=1}^N l_n,  &\n",
      "            \\text{if reduction} = \\text{`sum'.}\n",
      "        \\end{cases}\n",
      "\n",
      "  Note that this case is equivalent to applying :class:`~torch.nn.LogSoftmax`\n",
      "  on an input, followed by :class:`~torch.nn.NLLLoss`.\n",
      "\n",
      "- Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
      "  are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
      "  :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "      l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\n",
      "\n",
      "  where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "\n",
      "  .. math::\n",
      "      \\ell(x, y) = \\begin{cases}\n",
      "          \\frac{\\sum_{n=1}^N l_n}{N}, &\n",
      "           \\text{if reduction} = \\text{`mean';}\\\\\n",
      "            \\sum_{n=1}^N l_n,  &\n",
      "            \\text{if reduction} = \\text{`sum'.}\n",
      "        \\end{cases}\n",
      "\n",
      ".. note::\n",
      "    The performance of this criterion is generally better when `target` contains class\n",
      "    indices, as this allows for optimized computation. Consider providing `target` as\n",
      "    class probabilities only when a single class label per minibatch item is too restrictive.\n",
      "\n",
      "Args:\n",
      "    weight (Tensor, optional): a manual rescaling weight given to each class.\n",
      "        If given, has to be a Tensor of size `C` and floating point dtype\n",
      "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "        the losses are averaged over each loss element in the batch. Note that for\n",
      "        some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "        when :attr:`reduce` is ``False``. Default: ``True``\n",
      "    ignore_index (int, optional): Specifies a target value that is ignored\n",
      "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "        losses are averaged or summed over observations for each minibatch depending\n",
      "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
      "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "        be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "        ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "        and :attr:`reduce` are in the process of being deprecated, and in\n",
      "        the meantime, specifying either of those two args will override\n",
      "        :attr:`reduction`. Default: ``'mean'``\n",
      "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "        become a mixture of the original ground truth and a uniform distribution as described in\n",
      "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "\n",
      "Shape:\n",
      "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of `K`-dimensional loss.\n",
      "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
      "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
      "    - Output: If reduction is 'none', shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of K-dimensional loss, depending on the shape of the input. Otherwise, scalar.\n",
      "\n",
      "\n",
      "    where:\n",
      "\n",
      "    .. math::\n",
      "        \\begin{aligned}\n",
      "            C ={} & \\text{number of classes} \\\\\n",
      "            N ={} & \\text{batch size} \\\\\n",
      "        \\end{aligned}\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # Example of target with class indices\n",
      "    >>> loss = nn.CrossEntropyLoss()\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
      "    >>> output = loss(input, target)\n",
      "    >>> output.backward()\n",
      "    >>>\n",
      "    >>> # Example of target with class probabilities\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "    >>> output = loss(input, target)\n",
      "    >>> output.backward()\n",
      "\u001b[1;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\programfiles\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    for i,(data,label) in enumerate(train_loader):\n",
    "        data,label=data.cuda(),label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=criterian(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()*data.size(0)\n",
    "        \n",
    "    train_loss=train_loss/len(train_loader.dataset)\n",
    "    print('Epoch:{} \\tTraining loss:{:.6f}'.format(epoch,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    cro=0\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    for i,(data,label) in enumerate(test_loader):\n",
    "        data,label=data.cuda(),label.cuda()\n",
    "        output=model(data)\n",
    "        loss=criterian(output,label)        \n",
    "        test_loss+=loss.item()*data.size(0)        \n",
    "        indexMax=output.argmax(1)\n",
    "        # print(indexMax)\n",
    "        # print(label)     \n",
    "        cro+=torch.sum(indexMax-label == 0)\n",
    "\n",
    "    test_loss=test_loss/len(test_loader.dataset)\n",
    "    print('\\t \\tTesting loss:{:.6f} \\t Acc:{:.3f}%'.format(test_loss,cro/len(test_loader.dataset)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \tTraining loss:0.829953\n",
      "\t \tTesting loss:0.597265 \t Acc:77.620%\n",
      "Epoch:2 \tTraining loss:0.552917\n",
      "\t \tTesting loss:0.496204 \t Acc:82.070%\n",
      "Epoch:3 \tTraining loss:0.481485\n",
      "\t \tTesting loss:0.443276 \t Acc:84.100%\n",
      "Epoch:4 \tTraining loss:0.438916\n",
      "\t \tTesting loss:0.404987 \t Acc:85.920%\n",
      "Epoch:5 \tTraining loss:0.407089\n",
      "\t \tTesting loss:0.378778 \t Acc:86.800%\n",
      "Epoch:6 \tTraining loss:0.384405\n",
      "\t \tTesting loss:0.357965 \t Acc:87.380%\n",
      "Epoch:7 \tTraining loss:0.366275\n",
      "\t \tTesting loss:0.345658 \t Acc:87.900%\n",
      "Epoch:8 \tTraining loss:0.352008\n",
      "\t \tTesting loss:0.335416 \t Acc:87.980%\n",
      "Epoch:9 \tTraining loss:0.337047\n",
      "\t \tTesting loss:0.328085 \t Acc:88.290%\n",
      "Epoch:10 \tTraining loss:0.325990\n",
      "\t \tTesting loss:0.315274 \t Acc:88.720%\n",
      "Epoch:11 \tTraining loss:0.317785\n",
      "\t \tTesting loss:0.310431 \t Acc:88.760%\n",
      "Epoch:12 \tTraining loss:0.309761\n",
      "\t \tTesting loss:0.298708 \t Acc:89.160%\n",
      "Epoch:13 \tTraining loss:0.298719\n",
      "\t \tTesting loss:0.299567 \t Acc:89.040%\n",
      "Epoch:14 \tTraining loss:0.294529\n",
      "\t \tTesting loss:0.287600 \t Acc:89.730%\n",
      "Epoch:15 \tTraining loss:0.286927\n",
      "\t \tTesting loss:0.286033 \t Acc:89.630%\n",
      "Epoch:16 \tTraining loss:0.279325\n",
      "\t \tTesting loss:0.279838 \t Acc:89.920%\n",
      "Epoch:17 \tTraining loss:0.275818\n",
      "\t \tTesting loss:0.275452 \t Acc:89.990%\n",
      "Epoch:18 \tTraining loss:0.267941\n",
      "\t \tTesting loss:0.272002 \t Acc:90.240%\n",
      "Epoch:19 \tTraining loss:0.263960\n",
      "\t \tTesting loss:0.271789 \t Acc:90.050%\n",
      "Epoch:20 \tTraining loss:0.259594\n",
      "\t \tTesting loss:0.263265 \t Acc:90.360%\n",
      "Epoch:21 \tTraining loss:0.255870\n",
      "\t \tTesting loss:0.259775 \t Acc:90.600%\n",
      "Epoch:22 \tTraining loss:0.250101\n",
      "\t \tTesting loss:0.256757 \t Acc:90.700%\n",
      "Epoch:23 \tTraining loss:0.245462\n",
      "\t \tTesting loss:0.252910 \t Acc:90.860%\n",
      "Epoch:24 \tTraining loss:0.240488\n",
      "\t \tTesting loss:0.252889 \t Acc:90.980%\n",
      "Epoch:25 \tTraining loss:0.237946\n",
      "\t \tTesting loss:0.253336 \t Acc:90.810%\n",
      "Epoch:26 \tTraining loss:0.234326\n",
      "\t \tTesting loss:0.249285 \t Acc:90.950%\n",
      "Epoch:27 \tTraining loss:0.229084\n",
      "\t \tTesting loss:0.245035 \t Acc:91.150%\n",
      "Epoch:28 \tTraining loss:0.228203\n",
      "\t \tTesting loss:0.241060 \t Acc:91.480%\n",
      "Epoch:29 \tTraining loss:0.221751\n",
      "\t \tTesting loss:0.241980 \t Acc:91.440%\n",
      "Epoch:30 \tTraining loss:0.220579\n",
      "\t \tTesting loss:0.238122 \t Acc:91.360%\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    train(i+1)\n",
    "    test(i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
